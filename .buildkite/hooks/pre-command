#!/bin/bash

set -euo pipefail

echo "Clean existing environment"

# TEST_ARTIFACTS is a generic folder for artifacts that need to be used during
# testing. It will be collected in the artifacts in the end.
# Note that this has to be defined in a hook, because in the pipeline the $PWD
# would be evaluated to early (at pipeline expansion) and thus it would possibly
# be the wrong value on the agent a step is actually executed.
export TEST_ARTIFACTS="$PWD/test_artifacts"

. .buildkite/hooks/pre-exit

# Make sure the test artifacts folder exitsts.
echo "Create test artifacts: mkdir -p $TEST_ARTIFACTS"
mkdir -p "$TEST_ARTIFACTS"

# Conditionally export ACCEPTANCE_ARTIFACTS it is needed for acceptance tests.
# We only export it for the new pipeline because the old pipeline has its own
# definition.
if [ "$BUILDKITE_PIPELINE_SLUG" == "scionproto2" ]; then
    export ACCEPTANCE_ARTIFACTS="$TEST_ARTIFACTS"
fi

echo "Starting bazel remote cache proxy"

# Start bazel remote cache proxy for S3
# Note that S3 keys are injected by buildkite, see
# https://buildkite.com/docs/pipelines/secrets#storing-secrets-with-the-elastic-ci-stack-for-aws
docker run -e BAZEL_REMOTE_S3_BUCKET=$BAZEL_REMOTE_S3_BUCKET\
           -e BAZEL_REMOTE_S3_ENDPOINT=s3.eu-central-1.amazonaws.com\
           -e BAZEL_REMOTE_S3_ACCESS_KEY_ID=$BAZEL_REMOTE_S3_ACCESS_KEY_ID\
           -e BAZEL_REMOTE_S3_SECRET_ACCESS_KEY=$BAZEL_REMOTE_S3_SECRET_ACCESS_KEY\
           --net=host --name bazel-remote-cache -d buchgr/bazel-remote-cache
